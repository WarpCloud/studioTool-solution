
1.inceptor_inceptor_table_only.json 跨租户表文件互导 

  wf内容: 通过sql任务 在源端创建orc表，导入数据，导出数据，再通过脚本任务，执行distcp 命令 拷贝数据到目标
          端hdfs，然后通过 sql任务，在目标端创建orc表，把拷贝过来的数据，导入到orc表中    inceptor-inceptor 跨租户表文件互导
		  
2.inceptor_inceptor_table_many.json  跨租户多表文件互导 
  
  wf内容: 通过sql任务 在源端创建3张orc表，导入数据，导出数据，再通过脚本任务，执行distcp 命令 拷贝数据到目标
          端hdfs，然后通过 sql任务，在目标端创建3张orc表，把拷贝过来的数据，导入到orc表中    inceptor-inceptor 跨租户多表文件互导



注意：
WF 参数解析：
${hostname_inceptor_A} 填写源端inceptor ip
${hostname_inceptor_B} 填写目标端inceptor ip
${hostname_distcp_A} 填写源端namenode hdfs ip
${hostname_distcp_B} 填写目标端namenode hdfs ip
${guardian_token} 填写源端inceptor guardian token

如果试用wf的脚本任务，但是同时需要调用hdfs等客户端，可以试用tdhclient，具体操作可详见workflow的操作文档，下面简单描述：
1 需要把TDH-client.tar 添加到/var/lib/workflow{id}/ 目录下
2 并重启workflow服务，才能source TDH-client 成功

只支持从安全到不开安全的distcp,不支持不开安全到开安全的，执行distcp 添加的参数：
-Dipc.client.fallback-to-simple-auth-allowed=true  这个参数不支持 源端和目标端都不开安全的环境，或者源端和目标端都开安全的环境
例如:hadoop distcp  -Dipc.client.fallback-to-simple-auth-allowed=true hdfs://node089:8020/sql_hbase hdfs://172.26.5.39:8020/test_data
	
